{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'ms-gen-new (Python 3.8.18)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Cannot find module '@jupyterlab/services'\n",
      "\u001b[1;31mRequire stack:\n",
      "\u001b[1;31m- /mnt/home/magled/.cursor-server/extensions/ms-toolsai.jupyter-2024.11.0-linux-x64/dist/extension.node.js\n",
      "\u001b[1;31m- /mnt/home/magled/.cursor-server/extensions/ms-toolsai.jupyter-2024.11.0-linux-x64/dist/extension.node.proxy.js\n",
      "\u001b[1;31m- /mnt/home/magled/.cursor-server/cli/servers/Stable-96e5b01ca25f8fbd4c4c10bc69b15f6228c80770/server/out/vs/workbench/api/node/extensionHostProcess.js"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from rdkit import Chem\n",
    "import os\n",
    "import matplotlib\n",
    "from ms_pred.common import mass_from_smi\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Data from ICEBERG inference (obtained when running notebooks/iceberg_analysis.py)\n",
    "Replace `SAVE_PATH` with custom data from inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"/home/magled/results/20241129\" # NIST'20 test dataset\n",
    "\n",
    "# LIST OF FILE NAMES is all .csv files in the directory SAVE_PATH\n",
    "LIST_OF_FILE_NAMES = [f for f in os.listdir(SAVE_PATH) if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(save_path: str, file_name: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(f\"{save_path}/{file_name}\")\n",
    "\n",
    "def load_data_accumulative(save_path: str, file_names: list) -> pd.DataFrame:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    not_found_files = 0\n",
    "\n",
    "    for file_name in tqdm(file_names, desc=\"Loading files\", unit=\"file\"):\n",
    "        try:\n",
    "            df = pd.concat([df, load_data(save_path, file_name)])\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {file_name} not found\")\n",
    "            not_found_files += 1\n",
    "    print (f\"Number of not found files: {not_found_files}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data -- might take up to an hour to load all files!\n",
    "data = load_data_accumulative(SAVE_PATH, LIST_OF_FILE_NAMES)\n",
    "collision_energies = sorted(data['collision_energy'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where row['smiles'] has more than 10 heavay atoms\n",
    "data = data[data['smiles'].apply(lambda x: len(Chem.MolFromSmiles(x).GetAtoms()) <= 10)]\n",
    "# show rows where any entry is NaN\n",
    "data[data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where abs(mz-common.mass_from_smi(row(smiles)) < 1)\n",
    "data['mass_from_smi'] = data['smiles'].apply(lambda x: mass_from_smi(x))\n",
    "data['abs_diff'] = abs(data['mz'] - data['mass_from_smi'])\n",
    "data_new = data[data['abs_diff'] > 1.1]\n",
    "# remove rows where smiles is CS(=O)(=O)O (this molecule causes issues in fragmentation because no fragmentation is predicted --> all SMARTS are empty)\n",
    "data_new = data_new[data_new['smiles'] != 'CS(=O)(=O)O']\n",
    "data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to extract the bond types, atom types and plot the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bond_type(bond_obj: Chem.Bond) -> str:\n",
    "    \"\"\"\n",
    "    Get the bond type as a string representation.\n",
    "    \n",
    "    Args:\n",
    "        bond_obj (Chem.Bond): The bond object from RDKit.\n",
    "    \n",
    "    Returns:\n",
    "        str: The bond type as a string.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        Chem.BondType.SINGLE: '-',\n",
    "        Chem.BondType.DOUBLE: '=',\n",
    "        Chem.BondType.TRIPLE: '#',\n",
    "        Chem.BondType.AROMATIC: ':'\n",
    "    }.get(bond_obj.GetBondType(), '~')\n",
    "\n",
    "def get_neighbor_info(mol, atom_idx, exclude_idx) -> List[Tuple[str, str, int]]:\n",
    "    \"\"\"\n",
    "    Get information about neighboring atoms of a given atom in the molecule.\n",
    "\n",
    "    Args:\n",
    "        mol (Chem.Mol): The RDKit molecule object.\n",
    "        atom_idx (int): The index of the atom to analyze.\n",
    "        exclude_idx (int): The index of the atom to exclude from neighbors.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, str, int]]: A list of tuples containing the symbol, bond type, and index of each neighbor.\n",
    "    \"\"\"\n",
    "    neighbors = []\n",
    "    for bond in mol.GetAtomWithIdx(atom_idx).GetBonds():\n",
    "        neigh = bond.GetOtherAtom(mol.GetAtomWithIdx(atom_idx))\n",
    "        if neigh.GetIdx() != exclude_idx and neigh.GetAtomicNum() > 1:\n",
    "            bond_type = get_bond_type(bond)\n",
    "            neighbors.append((neigh.GetSymbol(), bond_type, neigh.GetIdx()))\n",
    "    return sorted(neighbors, key=lambda x: x[2])\n",
    "\n",
    "def create_bond_string(mol, idx1, idx2, include_env: int = 0) -> str:\n",
    "    \"\"\"\n",
    "    Create a string representation of a bond between two atoms in a molecule.\n",
    "\n",
    "    Args:\n",
    "        mol (Chem.Mol): The RDKit molecule object.\n",
    "        idx1 (int): The index of the first atom.\n",
    "        idx2 (int): The index of the second atom.\n",
    "        include_env (int): Flag to include environment information \"degree/coordination shere\" (0, 1, or 2).\n",
    "\n",
    "    Returns:\n",
    "        str: The bond string representation.\n",
    "    \"\"\"\n",
    "    atom1, atom2 = mol.GetAtomWithIdx(idx1), mol.GetAtomWithIdx(idx2)\n",
    "    symbol1, symbol2 = atom1.GetSymbol(), atom2.GetSymbol()\n",
    "    bond_type = get_bond_type(mol.GetBondBetweenAtoms(idx1, idx2))\n",
    "    \n",
    "    if include_env == 2:\n",
    "        neighbors1 = get_neighbor_info(mol, idx1, idx2)\n",
    "        neighbors2 = get_neighbor_info(mol, idx2, idx1)\n",
    "        \n",
    "        env1 = ''.join(f\"({n[0]}{n[1]})\" for n in neighbors1)\n",
    "        env2 = ''.join(f\"({n[0]}{n[1]})\" for n in neighbors2)\n",
    "        \n",
    "        bond_string1 = f\"{env1}{symbol1}{bond_type}{symbol2}{env2}\"\n",
    "        bond_string2 = f\"{env2}{symbol2}{bond_type}{symbol1}{env1}\"\n",
    "        return min(bond_string1, bond_string2)\n",
    "    elif include_env == 1:\n",
    "        return f\"{min(symbol1, symbol2)}{bond_type}{max(symbol1, symbol2)}\"\n",
    "    elif include_env == 0:\n",
    "        return f\"{min(symbol1, symbol2)}~{max(symbol1, symbol2)}\"\n",
    "    else:\n",
    "        print(\"Invalid value for include_env. Must be 0, 1, or 2.\")\n",
    "\n",
    "def analyze_bonds(df: pd.DataFrame, include_environment: int = 0) -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Analyzes bonds purely based on fragment and complement SMARTS patterns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data to analyze.\n",
    "        include_environment (int): Flag to include environment information \"degree/coordination shere\" (0, 1, or 2).\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[str, float]]: A dictionary containing the analysis results.\n",
    "    \"\"\"\n",
    "    bond_break_counts = defaultdict(int)          \n",
    "    bond_intensities = defaultdict(float)         \n",
    "    bond_occurrences = defaultdict(int)     \n",
    "    total_break_intensity = 0                     \n",
    "    max_intensity = 0\n",
    "    \n",
    "    # First pass: count total occurrences of each bond type in structures using SMILES\n",
    "    processed_smiles = set()\n",
    "\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc='First pass'):\n",
    "        smiles = row.get('smiles', None)\n",
    "        if smiles and smiles not in processed_smiles:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                continue\n",
    "                \n",
    "            processed_smiles.add(smiles)\n",
    "            \n",
    "            for bond in mol.GetBonds():\n",
    "                idx1, idx2 = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "                bond_string = create_bond_string(mol, idx1, idx2, include_env=include_environment)\n",
    "                bond_occurrences[bond_string] += 1\n",
    "\n",
    "    # Second pass: analyze fragmentations using fragment comparison\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc='Second pass'):\n",
    "        # Get the main molecule structure\n",
    "        mol = Chem.MolFromSmarts(row['smarts'])\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        # Get fragment and complement molecules\n",
    "        fragment_mol = Chem.MolFromSmarts(row['fragment_smarts'])\n",
    "        complement_mol = Chem.MolFromSmarts(row['complement_smarts'])\n",
    "        \n",
    "        if fragment_mol is None or complement_mol is None:\n",
    "            continue\n",
    "            \n",
    "        # Get mapped atoms in each part\n",
    "        fragment_atoms = {atom.GetAtomMapNum() for atom in fragment_mol.GetAtoms() \n",
    "                        if atom.GetAtomMapNum() != 0}\n",
    "        complement_atoms = {atom.GetAtomMapNum() for atom in complement_mol.GetAtoms() \n",
    "                        if atom.GetAtomMapNum() != 0}\n",
    "        \n",
    "        # For each bond in the main molecule\n",
    "        for bond in mol.GetBonds():\n",
    "            begin_atom = bond.GetBeginAtom()\n",
    "            end_atom = bond.GetEndAtom()\n",
    "            begin_map = begin_atom.GetAtomMapNum()\n",
    "            end_map = end_atom.GetAtomMapNum()\n",
    "            \n",
    "            # Skip if either atom isn't mapped\n",
    "            if begin_map == 0 or end_map == 0:\n",
    "                continue\n",
    "                \n",
    "            # Check if this bond crosses between fragment and complement\n",
    "            if ((begin_map in fragment_atoms and end_map in complement_atoms) or\n",
    "                (end_map in fragment_atoms and begin_map in complement_atoms)):\n",
    "                \n",
    "                # This is a breaking bond!\n",
    "                bond_string = create_bond_string(mol, bond.GetBeginAtomIdx(), \n",
    "                                            bond.GetEndAtomIdx(), include_environment)\n",
    "                \n",
    "                bond_break_counts[bond_string] += 1\n",
    "                bond_intensities[bond_string] += row['intensity']\n",
    "                total_break_intensity += row['intensity']\n",
    "                if row['intensity'] > max_intensity:\n",
    "                    max_intensity = row['intensity']\n",
    "\n",
    "    total_structural_bonds = sum(bond_occurrences.values())\n",
    "    total_breaks = sum(bond_break_counts.values())\n",
    "    \n",
    "    normalized_intensities = {\n",
    "        bond: intensity / bond_occurrences.get(bond, 1)\n",
    "        for bond, intensity in bond_intensities.items()\n",
    "    }\n",
    "    \n",
    "    total_normalized_intensity = sum(normalized_intensities.values())\n",
    "    \n",
    "    # Which bonds are intrinsically most likely to break, regardless of how many times they appear in the structure?\n",
    "    # P-score = normalized intensity contribution per unique bond occurrence\n",
    "    preferential_score = {\n",
    "        bond: (norm_intensity / total_normalized_intensity) * 100\n",
    "        for bond, norm_intensity in normalized_intensities.items()\n",
    "    }\n",
    "\n",
    "    # In this implementation, we exclusively show the preferential score (pScore).\n",
    "    return {\n",
    "        'preferential_score': dict(preferential_score),\n",
    "    }\n",
    "\n",
    "def prepare_data(data, analyze_bonds_func, metrics_to_look_at):\n",
    "    \"\"\"\n",
    "    Prepares data for analysis by grouping it by collision energy and analyzing bonds.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): The input data to analyze.\n",
    "        analyze_bonds_func (function): The function to analyze bonds.\n",
    "        metrics_to_look_at (list): List of metrics to include in the analysis.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[Dict[str, pd.DataFrame], List[float], List[str]]: A tuple containing:\n",
    "        - A dictionary of DataFrames for each metric.\n",
    "        - A list of unique collision energies.\n",
    "        - A list of unique bond types.\n",
    "        \n",
    "    \"\"\"\n",
    "    collision_energies = sorted(data['collision_energy'].unique())\n",
    "    \n",
    "    # First get all results for each collision energy\n",
    "    all_results = {ce: analyze_bonds_func(data[data['collision_energy'] == ce]) \n",
    "                  for ce in collision_energies}\n",
    "    \n",
    "    # Get ALL bond types from bond_occurences\n",
    "    all_bond_types = set()\n",
    "    for result in all_results.values():\n",
    "        all_bond_types.update(result['bond_occurences'].keys())\n",
    "        # Also include bond types from other metrics if needed\n",
    "        if 'bond_occurences' not in metrics_to_look_at:\n",
    "            for metric in metrics_to_look_at:\n",
    "                all_bond_types.update(result[metric].keys())\n",
    "    \n",
    "    # Create DataFrames\n",
    "    result_dfs = {}\n",
    "    for result_type in metrics_to_look_at:\n",
    "        # For other metrics, keep original behavior\n",
    "        df_data = {ce: {bt: 0.0 for bt in all_bond_types} \n",
    "                    for ce in collision_energies}\n",
    "        \n",
    "        for ce, result in all_results.items():\n",
    "            for bt, value in result[result_type].items():\n",
    "                df_data[ce][bt] = value\n",
    "        \n",
    "        result_dfs[result_type] = pd.DataFrame(df_data).T\n",
    "    \n",
    "    return result_dfs, collision_energies, list(sorted(all_bond_types))\n",
    "\n",
    "\n",
    "def plot_3d_by_bond(grouped_data, collision_energies, bond_types, result_type,\n",
    "                    cmap='viridis', figsize=(12,8)):\n",
    "    # ---- prepare display_data as before ----\n",
    "    display_data = (grouped_data[bond_types]\n",
    "                    .sort_index()\n",
    "                    .fillna(0))\n",
    "\n",
    "    display_data = display_data.div(display_data.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # numeric arrays\n",
    "    #Y = np.array(collision_energies, dtype=float)    # now the vertical axis\n",
    "    Y = np.arange(len(collision_energies))\n",
    "    n_e, n_b = display_data.shape                    # (#energies, #bonds)\n",
    "\n",
    "    # X axis will be just integer indices for each bond type\n",
    "    X_idx = np.arange(n_b)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize, dpi=400)\n",
    "    ax  = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # set up your axes ticks & labels\n",
    "    ax.set_xticks(X_idx)\n",
    "    ax.set_xticklabels(display_data.columns)\n",
    "    ax.set_yticks(Y)\n",
    "    ax.set_yticklabels(collision_energies)\n",
    "    ax.set_xlabel('Bond type')\n",
    "    ax.set_ylabel('Collision energy (eV)')\n",
    "    ax.set_zlabel('Average contribution\\nto intensity (%)')\n",
    "    ax.xaxis.labelpad=-3\n",
    "    ax.yaxis.labelpad=-3\n",
    "    ax.zaxis.labelpad=-3\n",
    "\n",
    "    # color normalization over bond types\n",
    "    norm      = plt.Normalize(0, n_b - 1)\n",
    "    cmap_inst = plt.get_cmap(cmap)\n",
    "\n",
    "    # for each bond type, build and draw its \"curtain\" + top edge\n",
    "    for i, bond in enumerate(display_data.columns):\n",
    "        zs = display_data[bond].values\n",
    "        xs = np.full_like(Y, i, dtype=float)\n",
    "\n",
    "        # build the “curtain” polygon\n",
    "        top    = np.column_stack((xs,       Y,       zs))\n",
    "        bottom = np.column_stack((xs[::-1], Y[::-1], np.zeros_like(zs)))\n",
    "        verts  = np.vstack((top, bottom))\n",
    "\n",
    "        poly = Poly3DCollection([verts], alpha=0.2)\n",
    "        color = cmap_inst(norm(i))\n",
    "        poly.set_facecolor(color)\n",
    "        poly.set_edgecolor('none')\n",
    "        ax.add_collection3d(poly)\n",
    "\n",
    "        # draw its 3D line on top\n",
    "        ax.plot(xs, Y, zs, color=color, linewidth=0.8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig('preferential.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot \"first\" coordination sphere\n",
    "\n",
    "Give scores for environments such as C-C, C:C, C=O, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plotting without environment\n",
    "data_frames_1, collision_energies_1, bond_types_1 = prepare_data(data, lambda df: analyze_bonds(df, include_environment=1), metrics_to_look_at=metrics_to_look_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_3d_by_bond(data_frames_1[result_type], collision_energies_1, ['C:N', 'C:C', 'C-O', 'C=O', 'C-N', 'C-C'], 'preferential_score', cmap='viridis', \n",
    "                figsize=(2,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-gen-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
