launcher_args: {experiment_name: scarf_canopus_train_public,
  script_name: "src/ms_pred/scarf_pred/train_gen.py",
  slurm_script: launcher_scripts/generic_slurm.sh, 
  launch_method: local,
  visible_devices: [1]
}
universal_args:
  _slurm_args:
  - {_num_gpu: 1, cpus-per-task: 7, job-name: forward_train, mem-per-cpu: 8G, #nodelist: 'node[1236]',
    time: '1-18:00:00'}
  debug: [false]
  gpu: [true]

  seed: [1]
  num-workers: [10] #[20]
  batch-size: [16]
  max-epochs: [200]

  dataset-name: [canopus_train_public]
  split-name: [split_1.tsv] #[split_1.tsv, split_2.tsv, split_3.tsv]

  learning-rate: [0.000577]
  lr-decay-rate: [0.894]

  dropout: [0.3]
  mpnn-type: [GGNN]
  pe-embed-k: [20]
  pool-op: [avg]
  hidden-size: [512]
  weight-decay: [1.0e-06]
  set-layers: [0]
  mlp-layers: [2]
  gnn-layers: [4]

  loss-fn: [bce]
  use-reverse: [true]
  formula-folder: [magma_subform_50]
  embedder: [abs-sines]
  use-tbc: [true]
  info-join: ["concat"]
  embed-adduct: [true]


iterative_args:
  -  split-name: [split_1.tsv]
     save-dir: [split_1]

  #-  split-name: [hyperopt.tsv]
  #   save-dir: [hyperopt]
