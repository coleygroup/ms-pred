launcher_args: {experiment_name: scarf_nist_hplus_fp,
  script_name: "src/ms_pred/scarf_pred/train_gen.py",
  slurm_script: launcher_scripts/generic_slurm.sh, 
  launch_method: local,
  visible_devices: [3]
}
universal_args:
  _slurm_args:
  - {_num_gpu: 1, cpus-per-task: 7, job-name: forward_train, mem-per-cpu: 8G, #nodelist: 'node[1236]',
    time: '1-18:00:00'}
  debug: [false]
  gpu: [true]

  seed: [1]
  num-workers: [10] #[20]
  batch-size: [32]
  max-epochs: [200]

  dataset-name: [nist20_hplus]
  split-name: [split_1.tsv] #[split_1.tsv, split_2.tsv, split_3.tsv]

  learning-rate: [0.000389]
  lr-decay-rate: [0.778048]

  dropout: [0.1]
  mpnn-type: [GINE]
  pe-embed-k: [10]
  pool-op: [avg]
  hidden-size: [256]
  weight-decay: [1.0e-07]
  set-layers: [0]
  mlp-layers: [3]
  #gnn-layers: [4]
  ## Use 2 bc this is the MLP
  gnn-layers: [2]

  loss-fn: [bce]
  use-reverse: [true]
  formula-folder: [magma_subform_50]
  embedder: [binary]
  use-tbc: [true]
  residual-connections: [true]
  option-dropout: [0.0]
  diff-dropout: [0.0]
  root-embedder: [fp]


iterative_args:
  -  split-name: [split_1.tsv]
     save-dir: [split_1]
