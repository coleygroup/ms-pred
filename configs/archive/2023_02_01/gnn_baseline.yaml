launcher_args: {experiment_name: gnn_baseline,
  script_name: "src/ms_pred/gnn_pred/train.py",
  slurm_script: launcher_scripts/generic_slurm.sh, 
  launch_method: local_parallel,
  visible_devices: [1, 2, 3]
}
universal_args:
  _slurm_args:
  - {_num_gpu: 1, cpus-per-task: 7, job-name: forward_train, mem-per-cpu: 8G, #nodelist: 'node[1236]',
    time: '1-18:00:00'}
  debug: [false]
  gpu: [true]

  seed: [1]
  num-workers: [16]
  batch-size: [64]
  max-epochs: [200]

  dataset-name: [canopus_train_public]
  split-name: [split_1.tsv] 

  learning-rate: [0.000138]
  lr-decay-rate: [0.799]
  num-bins: [10000] 
  loss-fn: [cosine]

  dropout: [0.0]
  mpnn-type: [GGNN]
  pe-embed-k: [14]
  pool-op: [attn]
  set-layers: [1]
  hidden-size: [128]
  use-reverse: [true]
  weight-decay: [0]
  layers: [4]

  form-dir-name: ['no_subform']

iterative_args:
  -  split-name: [split_1.tsv]
     save-dir: [split_1]
  -  split-name: [split_2.tsv]
     save-dir: [split_2]
  -  split-name: [split_3.tsv]
     save-dir: [split_3]
